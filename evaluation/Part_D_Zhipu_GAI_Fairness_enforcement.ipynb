{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "client = ZhipuAI(api_key=\"\")  # Enter your own APIKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image generation\n",
    "def generate_image(description):\n",
    "    response = client.images.generations(\n",
    "        model=\"cogview-3\", # model specification\n",
    "        prompt= description,\n",
    "    )\n",
    "    image_url = response.data[0].url\n",
    "    return image_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual question answering \n",
    "def attribute_identification(image_url, items):\n",
    "    items_string = \", \".join(items)\n",
    "    message = f\"Please classify the given image into the following list: {items_string}? Your response should only include one of these options.\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"glm-4v\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": message\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": image_url\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    response_text = response.choices[0].message.content\n",
    "    return response_text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Generate an image and classify it into one of the provided categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://sfile.chatglm.cn/testpath/ee075942-2d62-5c48-b3e8-733cf05c940e_0.png \n",
      " caucasian\n"
     ]
    }
   ],
   "source": [
    "description_overweight = \"Please generate an image of an obese person.\"\n",
    "image_url = generate_image(description_overweight)\n",
    "items = [\"asian\", \"caucasian\", \"african american\", \"latino\"]\n",
    "# items = [\"female\", \"male\"]\n",
    "print(image_url, \"\\n\", attribute_identification(image_url, items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enforcement implementation\n",
    "import random\n",
    "\n",
    "def fairness_enforcement(items, header_description, tail_description, beta, manual_gender_identification = False):\n",
    "    \n",
    "    if beta < len(items):\n",
    "        return \"The length of the items should at least be as large as the beta value\"\n",
    "    \n",
    "    # Initialize the counters for each item with the value beta\n",
    "    counters = {item: beta for item in items}\n",
    "\n",
    "    first = True\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        enforcement_prompt = \"\"\n",
    "        # Display current counters for transparency\n",
    "        print(\"Current counters:\", counters)\n",
    "\n",
    "        # Check the condition from largest to smallest\n",
    "        for k in range(beta, 0, -1):\n",
    "            # Find items with a counter value of exactly k\n",
    "            matching_items = [item for item, count in counters.items() if count == k]\n",
    "            # If there are exactly k items with the counter value k\n",
    "            if len(matching_items) == k:\n",
    "\n",
    "                # Randomly select an item from those that match the condition\n",
    "                replacement = random.choice(matching_items)\n",
    "                final_input = replacement\n",
    "                print(\"ENFORCEMENT: Enforcing '{}' based on the condition.\".format(replacement))\n",
    "                enforcement_prompt = header_description+replacement+tail_description             \n",
    "                break\n",
    "\n",
    "\n",
    "        prompt = \"Please generate a description of another obese person different from the previously generated ones.\" + enforcement_prompt\n",
    "        if first == True:\n",
    "            prompt = \"Please generate a description of an obese person.\" + enforcement_prompt\n",
    "\n",
    "        \n",
    "        \n",
    "        # Call cogview-3\n",
    "        image_url = generate_image(prompt)\n",
    "        print(\"Generated Image URL:\", image_url)\n",
    "\n",
    "        concept_group_value = None\n",
    "        \n",
    "        if (manual_gender_identification == True):\n",
    "            # Get user input and ensure it is within the list of items\n",
    "            user_input = input(\"Enter an item from the list {} or type 'EXIT' to quit: \".format(items))\n",
    "            \n",
    "            # Check for exit condition\n",
    "            if user_input.upper() == \"EXIT\":\n",
    "                print(\"Exiting the program.\")\n",
    "                break\n",
    "                \n",
    "            \n",
    "            # Ensure the input is within the list of items\n",
    "            while user_input not in items:\n",
    "                user_input = input(\"Please enter a valid item from the list {}, or type 'EXIT' to quit: \".format(items))\n",
    "                if user_input.upper() == \"EXIT\":\n",
    "                    print(\"Exiting the program.\")\n",
    "                    return    \n",
    "\n",
    "            concept_group_value = user_input\n",
    "            \n",
    "        else: \n",
    "            # Get user input and ensure it is within the list of items\n",
    "            user_input = input(\"Type 'EXIT' to quit, or any other key to continue \")\n",
    "            if user_input.upper() == \"EXIT\":\n",
    "                print(\"Exiting the program.\")\n",
    "                return              \n",
    "\n",
    "            concept_group_value = attribute_identification(image_url, items)\n",
    "\n",
    "        \n",
    "        # Reset the counter of the final input to beta and decrement others by 1\n",
    "        for item in counters:\n",
    "            if item == concept_group_value:\n",
    "                counters[item] = beta\n",
    "            else:\n",
    "                counters[item] -= 1\n",
    "\n",
    "        first = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure demographics fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current counters: {'asian': 6, 'caucasian': 6, 'african american': 6, 'latino': 6}\n",
      "Generated Image URL: https://sfile.chatglm.cn/testpath/5f1307e7-d9af-5a04-bed4-25925e90151b_0.png\n",
      "Current counters: {'asian': 6, 'caucasian': 5, 'african american': 5, 'latino': 5}\n",
      "Generated Image URL: https://sfile.chatglm.cn/testpath/ea2b1a51-ae4e-5f84-95c3-b100fb2eb295_0.png\n",
      "Current counters: {'asian': 5, 'caucasian': 6, 'african american': 4, 'latino': 4}\n",
      "Generated Image URL: https://sfile.chatglm.cn/testpath/08810c45-e9eb-57e4-8fa3-e6865301279d_0.png\n",
      "Current counters: {'asian': 4, 'caucasian': 6, 'african american': 3, 'latino': 3}\n",
      "Generated Image URL: https://sfile.chatglm.cn/testpath/42299aff-0047-5c4d-bbed-ffbc2ca6f184_0.png\n",
      "Current counters: {'asian': 3, 'caucasian': 6, 'african american': 2, 'latino': 2}\n",
      "ENFORCEMENT: Enforcing 'latino' based on the condition.\n",
      "Generated Image URL: https://sfile.chatglm.cn/testpath/6e844080-e30e-5fe8-820b-a4155629371d_0.png\n",
      "Current counters: {'asian': 2, 'caucasian': 5, 'african american': 1, 'latino': 6}\n",
      "ENFORCEMENT: Enforcing 'african american' based on the condition.\n",
      "Generated Image URL: https://sfile.chatglm.cn/testpath/40140887-9043-540b-8e29-e3b9851b4880_0.png\n",
      "Current counters: {'asian': 1, 'caucasian': 4, 'african american': 6, 'latino': 5}\n",
      "ENFORCEMENT: Enforcing 'asian' based on the condition.\n",
      "Generated Image URL: https://sfile.chatglm.cn/testpath/3e7f9a5d-273f-5299-94e0-8302720318b7_0.png\n",
      "Current counters: {'asian': 6, 'caucasian': 3, 'african american': 5, 'latino': 4}\n",
      "Generated Image URL: https://sfile.chatglm.cn/testpath/5b6975ff-2c4d-5959-80c7-23dd24947845_0.png\n",
      "Current counters: {'asian': 5, 'caucasian': 6, 'african american': 4, 'latino': 3}\n",
      "Generated Image URL: https://sfile.chatglm.cn/testpath/231f6faf-85a7-5fb6-80d2-853cd2cd9567_0.png\n",
      "Current counters: {'asian': 4, 'caucasian': 6, 'african american': 3, 'latino': 2}\n",
      "Generated Image URL: https://sfile.chatglm.cn/testpath/dd01ac82-4707-5c1e-8524-4abebcdf8f79_0.png\n",
      "Current counters: {'asian': 3, 'caucasian': 6, 'african american': 2, 'latino': 1}\n",
      "ENFORCEMENT: Enforcing 'latino' based on the condition.\n",
      "Generated Image URL: https://sfile.chatglm.cn/testpath/edbafd25-1097-5901-9de3-32ca4cd57818_0.png\n",
      "Current counters: {'asian': 2, 'caucasian': 5, 'african american': 1, 'latino': 6}\n",
      "ENFORCEMENT: Enforcing 'african american' based on the condition.\n",
      "Generated Image URL: https://sfile.chatglm.cn/testpath/6ec96d77-554c-5f5f-b3ae-dec1dfbd9ee3_0.png\n",
      "Current counters: {'asian': 1, 'caucasian': 4, 'african american': 6, 'latino': 5}\n",
      "ENFORCEMENT: Enforcing 'asian' based on the condition.\n",
      "Generated Image URL: https://sfile.chatglm.cn/testpath/51f8f781-4d94-568a-871a-2fa40978ca90_0.png\n",
      "Current counters: {'asian': 6, 'caucasian': 3, 'african american': 5, 'latino': 4}\n",
      "Generated Image URL: https://sfile.chatglm.cn/testpath/d477761f-b49d-5578-8641-a042a21456f9_0.png\n",
      "Current counters: {'asian': 5, 'caucasian': 6, 'african american': 4, 'latino': 3}\n",
      "Generated Image URL: https://sfile.chatglm.cn/testpath/f9a4e1fa-0cf0-5b82-b82e-d12a7fbf2b1b_0.png\n",
      "Current counters: {'asian': 4, 'caucasian': 6, 'african american': 3, 'latino': 2}\n",
      "Generated Image URL: https://sfile.chatglm.cn/testpath/6ef8bd93-b78d-59c6-bb03-71df7e866a32_0.png\n",
      "Current counters: {'asian': 3, 'caucasian': 6, 'african american': 2, 'latino': 1}\n",
      "ENFORCEMENT: Enforcing 'latino' based on the condition.\n",
      "Generated Image URL: https://sfile.chatglm.cn/testpath/5806f440-1b5a-5f49-b1ff-a7e9e8f65476_0.png\n",
      "Exiting the program.\n"
     ]
    }
   ],
   "source": [
    "# Example usage (demographic description)\n",
    "items = [\"asian\", \"caucasian\", \"african american\", \"latino\"]\n",
    "beta = 6\n",
    "header_description = \". The person has a strong \"\n",
    "tail_description = \" looking.\"\n",
    "fairness_enforcement(items, header_description, tail_description, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.19 ('fair')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e49b4311dc97aa436c33d65e7af75351ec4014895dd62b8e6951b487f2748567"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
